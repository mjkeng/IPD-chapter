---
title: "Modelling with individual patient data"
author: "Mi Jun Keng, Iryna Schlackow, Eleanor Pullenayegum"
date: "`r Sys.Date()`"
output: 
  bookdown::html_document2:
    toc: true
    toc_float: true
bibliography: [references.bib, packages.bib]
editor_options: 
  chunk_output_type: console
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

## Include packages here to automatically generate reference
knitr::write_bib(c('tableone', 'qwraps2', 'DescTools'), 'packages.bib')

```


# Introduction 


Analysis using individual patient data comes with the benefits afforded by the type of analysis that can be performed, and the ability to capture patient heterogeneity. 
However, there are practical and methodological challenges involved. 
Practically, there could be issues with privacy, storage, and computational power required for handling and analysing large datasets. 
Methodological challenges include handling of missing data, choice of models to use for analysis etc. 

Data pre-processing is a critical component of data analysis, and is typically needed to derive variables of interest required for analysis.
It is unfortunately not always straight-forward, and can be time-consuming. 
For example, one may need to derive healthcare cost from records of prescriptions, GP visits and hospital visits, and these records may need to be extracted from different databases, which may all use different coding systems. 

Data exploration is then needed to help understand the structure of the data, identify outliers, understand relationship between variables etc. which subsequently informs how your research question can be addressed (e.g. what models to use given data distribution). 

In this chapter, we will demonstrate how to 

- manipulate dataset and construct key variables for analysis
- summarise data; perform descriptive analysis 
- perform frequentist cost-effectiveness analysis 
- perform Bayesian cost-effectiveness analysis 


# Case study: Cost-utility analysis of the Ten Top Tips trial

In this chapter, we will demonstrate the process of performing a within-trial cost-utility analysis using a simplified, synthetic dataset `10TT_synth_280921.csv` generated based on the Ten Top Tips (10TT) trial design [@beeken_brief_2017]. _This merely serves as a case study to illustrate the concepts of using individual patient data for analysis so methods and results may deviate from the published within-trial cost-effectiveness analysis of the trial [@patel_costeffectiveness_2018]._ 

The 10TT trial was a two-arm, individually randomised, controlled trial of a weight-loss intervention for obese adults attending general practices in the UK. 537 participants in the trial were randomised to receive either the 10TT intervention, or usual care from their general practices.
The intervention was designed to encourage forming of good habits through self-help materials including a leaflet with ten simple weight-control tips and a logbook to record participant's own progress. 

```{r}

## Load required packages
library(tidyverse)

## Specify file location 
wd <- getwd()
dir_data <- file.path(wd, "data")

## Read in dataset; sample of first 5 participant data
df <- read.csv(file.path(dir_data, "10TT_synth_280921.csv")) %>% 
  mutate(across(c("arm", "sex", "bmicat"), as.factor))

head(df, 5)

```

We will perform a within-trial cost-utility analysis to compare the costs and outcomes (i.e. QALYs) associated with 10TT and usual care.
The primary outcomes are incremental costs and effects and the incremental net monetary benefit (NMB) of 10TT versus usual care over the 2-year trial follow-up period.
Because of the short duration of the trial, no discounting will be applied. 
We consider cost-effectiveness thresholds of £20,000 and £30,000.
For the purpose of this chapter, we will be performing a complete case analysis so missing data will be excluded (more details on handling of missing data is available in the missing data chapter [@ref]). 


## Descriptive statistics 

We first start by producing descriptive statistics for the dataset. 
This can include sample size, measures of central tendancy (mean, median, mode), measures of variability (standard deviation, variance), dispersion of data (minimum, maximum, interquatile range), shape of distribution of data (skewness, kurtosis), and measures of dependence between variables (correlation, covariance). 
These can be presented as summary values in tabular form (typically "Table 1" in health research publications), or visualised graphically using histograms for example. 
Descriptive statistics are helpful to understand for example how your data is distributed, imbalances between treatment arms etc. which ultimately informs the analysis (choice of model to use or variables to include in model) and interpretation of results. 

It is possible to use base R or tidyverse to produce descriptive statistics, which gives you maximum control over how you want to summarise and present the data. There are also many packages that can help you do this (varying in ease of use and flexibility for customisation), including:
[qwraps2](https://cran.r-project.org/web/packages/qwraps2/vignettes/summary-statistics.html) [@R-qwraps2], 
[tableone](https://cran.r-project.org/web/packages/tableone/vignettes/introduction.html) [@R-tableone], 
[DescTools](https://andrisignorell.github.io/DescTools/) [@R-DescTools].

### Baseline demographics 

Here, we summarise participants' demographics at baseline, including sex (`sex = 1` Male, `sex = 2` Female), age, and BMI category (`bmicat = 1` < 35kg/m$^2$, `bmicat = 2` $\ge$ 35kg/m$^2$), separately for participants in the 10TT arm (`arm = 1`) and the usual care arm (`arm = 0`).

```{r}

tableone::CreateTableOne(vars = c("sex", "age", "bmicat"), strata = "arm", data = df, test = F)

```

---

Extra notes

Categorical variables in the dataset were coded in numerical values by default. 
This may be useful when you have a reference level in mind or for variables with natural ordering (e.g. from low to high BMI), since numerical values have natural ordering. 
However, sometimes, it might be more intuitive to have labels instead of numerical values. 
The levels are ordered alpha-numerically by default, but it is possible to specify your own order for the levels.
This can be changed accordingly in the data frame, which we will demonstrate with the `arm` variable in the dataset.  

```{r}

df_label <- df 

df_label$arm <- factor(df_label$arm, levels = c("1", "0"), labels = c("10TT", "Usual Care"), ordered = T)

tableone::CreateTableOne(vars = c("sex", "age", "bmicat"), strata = "arm", data = df_label, test = F)

```

---


### Utilities & QALYs

Participants completed the EQ-5D-3L questionnaire during study visits at baseline, and at 3, 6, 12, 18 and 24 months. These responses were mapped onto utility scores based on the UK tariffs [@addref21] (labelled `qol_X`, where `X` is the month of measurement).

```{r}

## Example of QoL data

df_qol <- df %>% 
  select(id, arm, contains("qol")) %>% 
  ## convert dataframe from wide to long format
  pivot_longer(contains("qol"), names_to = "month", names_prefix = "qol_", names_transform = list(month = as.integer), values_to = "qol")

head(df_qol, 5)

```


```{r, fig.cap = "Trend in QoL over time in each treatment arm"}

df_plot_qol <- df_qol %>% 
  group_by(arm, month) %>% 
  summarise(qol_mean = mean(qol, na.rm = T), qol_se = sqrt(var(qol, na.rm = T)/length(qol)))

ggplot(data = df_plot_qol, aes(color = arm, group = arm)) + 
  geom_point(aes(x = month, y = qol_mean, shape = arm)) + 
  geom_line(aes(x = month, y = qol_mean, group = arm, linetype = arm)) + 
  geom_errorbar(aes(x = month, ymin = qol_mean - 1.96 * qol_se, ymax = qol_mean + 1.96 * qol_se)) + 
  labs(x = "Month", y = "Mean QoL at each study visit (95% CI)") + 
  scale_x_continuous(breaks = c(0, 3, 6, 12, 18, 24))

# ggplot(data = df_qol, aes(x = month, y = qol, group = arm, color = arm)) +
#   stat_summary(geom = "pointrange", fun.data = "mean_cl_boot", na.rm = T, conf.int = .95, B = 1000)

```

---

Extra notes 

Since the trial had a relatively short duration (2 years), no discounting was applied for the analysis. However, discounting is typically required. Here, we demonstrate an example if we were to apply a 3.5% discount rate to quality of life data by pre-defining a function `disc` to perform discounting. 

```{r}

## Function to perform discounting
## Default discount rate set at 3.5% 
disc <- function(x, year, disc_rate = 0.035) {
  x / ((1 + disc_rate)^(year - 1))
}


## Apply discounting to QoL data
df_qol_disc <- df_qol %>% 
  ## convert month to follow-up year; set baseline to be in year 1
  mutate(year = pmax(1, ceiling(month/12))) %>% 
  ## apply discounting
  mutate(qol_disc = disc(qol, year)) 

df_qol_disc %>% 
  filter(id == 3)

```

---


A utility profile was constructed for participants assuming a straight-line relation between their utility values at each measurement point. 
QALYs for every patient from baseline to 2 years were calculated as the area under the utility profile.

```{r, fig.cap="Example of utility profile for participant ID 3. QALYs is the shaded region under the utility profile."}

## Example of QoL data for participant id 3

df_qol %>% 
  filter(id == 3)

ggplot(data = df_qol %>% filter(id == 3)) + 
  geom_line(aes(x = month, y = qol)) + 
  geom_ribbon(aes(x = month, ymax = qol, ymin = 0), fill = "red", alpha = 0.2) + 
  labs(x = "Month", y = "QoL") + 
  scale_x_continuous(breaks = c(0, 3, 6, 12, 18, 24))

```

```{r}

df_qaly <- df_qol %>% 
  group_by(id) %>% 
  ## exclude participants with missing qol at any visit
  filter(!any(is.na(qol))) %>% 
  # summarise(qaly = sum(diff(month) * (head(qol_disc, -1) + tail(qol_disc, -1)))) ## if base R
  ## calculate area under the utility profile
  summarise(qaly = DescTools::AUC(x = month, y = qol, method = "trapezoid") / 12) 

summary(df_qaly$qaly)

```

```{r}

df_qol_analysis <- df_qol %>% 
  select(id, month, qol) %>% 
  pivot_wider(names_from = "month", values_from = "qol", names_prefix = "qol_") %>% 
  left_join(df_qaly, by = "id")
  
```


### Resource use and costs

Data on healthcare resource use were extracted from general practitioner (GP) records over the 2-year study period, and costs were measured from a healthcare perspective. 
These include cost of GP visits (number of GP visits`gpvis` * £45/GP visit), cost of intervention (`costint` £22.90 for 10TT intervention), and cost of other healthcare resource use such as secondary care and practice nurse visits (`costoth`). 

```{r}

## Example of cost data

df_cost <- df %>% 
  select(id, arm, gpvis, contains("cost")) 

head(df_cost, 3)

```


```{r}

df_cost_analysis <- df_cost %>% 
  select(id, totalcost) %>% 
  rename(cost = totalcost)

```

---

Extra notes 

The dataset already contains the varaible total cost `totalcost`. We can do a quick check to see if this has been calculated correctly. 

```{r}

all.equal(df_cost$gpvis * 45 + df_cost$costint + df_cost$costoth, df_cost$totalcost)

```

---


```{r, fig.cap= "Distribution of cost"}

ggplot(data = df_cost_analysis) + 
  geom_histogram(aes(x = cost), binwidth = 250) + 
  labs(x = "Cost")

```

From the histogram, we see that the data is bounded below by zero and heavily skewed with long right hand tail, which are features typical of cost data.

### Analysis dataset

We now combine the datasets on patient characteristics `df`, cost `df_cost_analysis` and quality of life `df_qol_analysis` for further analysis. 

```{r}

df_analysis_withmissing <- df %>% 
  select(id, arm, sex, age, bmicat) %>% 
  left_join(df_qol_analysis, by = "id") %>% 
  left_join(df_cost_analysis, by = "id")

df_analysis_withmissing %>% 
  summarise(across(c("qaly", "cost"), ~ sum(is.na(.))))

```

There are 369 and 153 participants missing measures of quality of life and cost respectively. After excluding participants with missing data, 167 participants (31%) are included in our analysis, with 67 and 100 participants in the 10TT and usual care arms respectively.

```{r}

df_analysis <- df_analysis_withmissing %>% 
  drop_na() 

tableone::CreateTableOne(strata = "arm", data = df_analysis %>% select(-id), test = F)

```


```{r fig.cap= "Total cost and QALYs over 2 years of follow-up stratified by treatment arm"}

p <- ggplot(data = df_analysis, aes(group = arm, color = arm, fill = arm)) + 
  geom_point(aes(x = cost, y = qaly)) + 
  theme(legend.position = "bottom") + 
  labs(x = "Total cost (£)", y = "QALYs")

ggExtra::ggMarginal(p, groupColour = T, groupFill = T, alpha = 0.25)

```


```{r child = 'frequentist.Rmd'}
```


<!-- ```{r child = 'bayesian.Rmd'} -->
<!-- ``` -->


### References 

<div id="refs"></div>
